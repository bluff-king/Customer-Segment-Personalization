\begin{titlepage}

\begin{center}
 \textbf{HANOI UNIVERSITY OF SCIENCE AND TECHNOLOGY} \\
 \vspace{12pt}
\textbf{SCHOOL OF INFORMATION AND COMMUNICATION TECHNOLOGY}
\end{center}
 \vspace{20pt}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/logo-soict-hust.png}
    \label{fig:enter-label}
\end{figure}
%------------------------------------------------
%	Main part
%------------------------------------------------

\begin{center}
\vspace{10pt}
\begin{LARGE}
 \textbf{CUSTOMER SEGMENTATION \& PERSONALIZATION} \\   
\end{LARGE}
\vspace{20pt}
\begin{large}
    \textbf{BUSINESS DATA ANALYTICS}\\
\end{large}
\vspace{10pt}
\large \textbf{Supervisor:} Assoc. Prof. Nguyen Binh Minh \\
\vspace{20pt}
	

%------------------------------------------------
%	General information about the author
%------------------------------------------------+
\begin{table}[htpb!]
    \centering
    \begin{tabular}{l l l}
         \hspace{6pt} \textbf{\fontsize{10pt}{0pt}\selectfont \large Group 18:} \hspace{6pt}  & \fontsize{10pt}{0pt}\selectfont \text{ }\large Doan Anh Vu \hspace{15pt} & \fontsize{10pt}{0pt}\selectfont \large 20225465 \vspace{6pt}\\
         & \fontsize{10pt}{0pt} \selectfont \large Vu Trung Thanh \hspace{15pt} &\fontsize{10pt}{0pt}\selectfont \large 20220066 \vspace{6pt} \\
         & \fontsize{10pt}{0pt} \selectfont \large Luong Huu Thanh\hspace{15pt} &\fontsize{10pt}{0pt}\selectfont \large 20225458 \vspace{6pt} \\ 
         & \fontsize{10pt}{0pt} \selectfont \large Nguyen Mau Trung\hspace{15pt} &\fontsize{10pt}{0pt}\selectfont \large 20225534 \vspace{6pt} \\
    \end{tabular}
    
\end{table}
\vspace{100pt}
\begin{large}
    Hanoi, November 2025
\end{large}
\end{center}



\setcounter{page}{1}
\section{Introduction}
\label{sec:introduction}

In an increasingly competitive e-commerce environment, personalization has become a critical differentiator for improving customer engagement and sustaining long-term business performance. Understanding the nuances in customer behavior allows firms to transition from uniform marketing strategies toward targeted, data-driven actions. 

This project develops a comprehensive customer segmentation framework. By analyzing behavioral patterns-ranging from product views to transactions-we aim to identify distinct user cohorts. The resulting segmentation serves as the foundation for identifying customer personas and deploying tailored retention strategies, ultimately bridging the gap between raw data and actionable marketing intelligence.


\section{Business Understanding}
\label{sec:business_understanding}

\subsection{Project Context}
This project leverages the \textbf{RetailRocket E-commerce dataset}, comprised of real-world implicit feedback logs collected over a 4.5-month period. The dataset includes item views, add-to-cart events, and transactions, along with time-varying item attributes.

\textbf{Core Challenge:} The data is observational, static, and hashed for confidentiality. The primary challenge is to transform granular "clickstreams" into high-level "customer intelligence." We must infer user intent from behavioral traces to support decision-making, moving away from mass marketing towards personalized engagement.

\subsection{Business Goal}
The objective is to architect an end-to-end \textbf{Customer Segmentation \& Personalization System}. This system will enable the marketing team to optimize resource allocation by targeting specific user groups. 

\textbf{Key Deliverables:}
\begin{enumerate}
    \item \textbf{Segmentation Model:} A clustering-based approach (K-Means) categorizing customers based on RFM (Recency, Frequency, Monetary) indices and behavioral patterns.
    \item \textbf{CLV Prediction:} A probabilistic model (BG/NBD + Gamma-Gamma) to distinguish between "high-value" users and "churned" users.
    \item \textbf{Action Board (Strategic Mapping):} A defined set of rules mapping segments to marketing actions, derived from the DOC framework (detailed in Section \ref{sec:doc_framework}).
    \item \textbf{Experimentation Framework:} A design for future A/B testing, including control groups and success metrics, to validate segment-specific interventions.
    \item \textbf{Personalization Dashboard:} A visual interface for stakeholders to monitor segment health, migration trends, and revenue distribution.
\end{enumerate}

\subsection{The DOC Framework (Decision - Options - Criteria)}
\label{sec:doc_framework}
To align the technical solution with business needs, we apply the DOC framework:

\subsubsection{Decision}
\textbf{"What is the optimal engagement strategy for each specific customer segment to maximize retention and revenue?"}

\subsubsection{Options (Strategic Levers)}
We define four high-level strategic options based on customer behavior: 
\begin{itemize}
    \item \textbf{VIP Retention (Loyal Customers):}
    \begin{itemize}
        \item \textit{Action:} Exclusive early access, loyalty tiers, and value-added services (non-monetary incentives).
    \end{itemize}
    \item \textbf{Growth Acceleration (Promising Users):}
    \begin{itemize}
        \item \textit{Action:} Second-purchase incentives and cross-sell recommendations to increase frequency.
    \end{itemize}
    \item \textbf{Reactivation (Hibernating/At-Risk):}
    \begin{itemize}
        \item \textit{Action:} Time-limited aggressive discounts or "We miss you" campaigns.
    \end{itemize}
    \item \textbf{Acquisition/Conversion (Non-Transactors):}
    \begin{itemize}
        \item \textit{Action:} First-order discounts, onboarding flows, and social proofing.
    \end{itemize}
\end{itemize}

\subsubsection{Criteria (Success Metrics)}
\begin{enumerate}
    \item \textbf{Segmentation Interpretability:} Segments must have human-readable definitions (e.g., "Big Spenders") showing consistent and meaningful behavioral differences that can support business decision-making, rather than purely optimizing statistical metrics.
    \item \textbf{Business Actionability:} Each segment must be easily mapped to a distinct marketing strategy (e.g., retention, growth, reactivation), ensuring that the segmentation results are actionable in real-world marketing operations.
    % note: co the sai/k dung
    \item \textbf{Stability:} Segments should remain relatively stable over short periods to ensure consistent campaign execution.
    \item \textbf{Dashboard Effectiveness:} The dashboard should clearly communicate the segmentation insights, segment sizes, and proposed actions, enabling stakeholders to quickly understand customer distribution and prioritize interventions.
\end{enumerate}

\subsection{KPI Tree \& Metric Decomposition}
To measure the success of the proposed strategies, we structure our Key Performance Indicators (KPIs) starting from a North Star Metric. 

\subsubsection{North Star Metric: GMV (Gross Merchandise Value)}
The total value of merchandise sold over the period.
$$GMV = \text{Traffic} \times \text{Conversion Rate (CR)} \times \text{ATS}$$

\subsubsection{Metric 1: Conversion Rate (CR)}
The percentage of unique visitors who make at least one purchase. To identify specific points in the user journey, we decompose this into the following stages:

\begin{itemize}
    \item \textbf{View-to-Cart Rate:} The efficiency of moving users from product discovery to intent.
    \item \textbf{Cart-to-Transaction Rate:} The efficiency of the checkout process.
\end{itemize}

$$CR = \underbrace{\left( \frac{\text{Visitors who Add to Cart}}{\text{Total Unique Visitors}} \right)}_{\text{View } \to \text{ Add to Cart}} \times \underbrace{\left( \frac{\text{Unique Paying Visitors}}{\text{Visitors who Add to Cart}} \right)}_{\text{Add to Cart } \to \text{ Transaction}}$$

\subsubsection{Metric 2: Average Ticket Size (ATS)}

\textbf{Data Constraint:} The dataset logs individual item transactions (\texttt{visitorid}, \texttt{itemid}, \texttt{transactionid}) but does not strictly group them into "baskets" or "orders" with a unified Order ID. 

\textbf{Solution:} We use \textbf{Average Ticket Size (ATS)}-the average value generated per transaction event or per paying visitor-as a proxy for Average Order Value (AOV). This assumes that transaction events are a reliable proxy for purchase intent units.

$$ATS \approx \frac{\text{Total Revenue}}{\text{Total Paying Visitors}}$$

\subsection{Risks \& Mitigation}
\begin{itemize}
    \item \textbf{Assumption Validity:} The "ATS" proxy might underestimate value if users buy bundles in single logic flows we can't see.
    \item \textbf{Data Sparsity:} A significant portion of users may have only 1-2 interaction events.
    \begin{itemize}
        \item \textit{Mitigation:} Use "Cold Start" strategies (e.g., recommending popular items) for these users and exclude them from complex CLV modeling to avoid noise.
    \end{itemize}
    \item \textbf{Observational Bias:} As the dataset is historical, we cannot measure the \textit{causal} impact of proposed actions without a live test.
    \begin{itemize}
        \item \textit{Mitigation:} The "Experimentation Framework" deliverable explicitly designs the necessary control groups to validate strategies in a future deployment phase.
    \end{itemize}
\end{itemize}



\section{Data Understanding}
\label{sec:data_understanding}


This step involves describing data, exploring it, and verifying its quality. The goal is to gain insights into the data's content and structure to support the subsequent modeling phases.

\subsection{Data Description}

The analysis utilizes the \textbf{RetailRocket E-commerce dataset}, which consists of three primary data files. The data covers a period of approximately 4.5 months, from \textbf{May 2015 to September 2015}.

\begin{table}[h!]
\centering
\small
\begin{tabularx}{\textwidth}{|l|l|X|X|l|}
\hline
\textbf{Dataset} & \textbf{Filename} & \textbf{Description} & \textbf{Key Features} & \textbf{Size/Records} \\ \hline
\textbf{Events} & \texttt{events.csv} & Captures user interactions with items. & \texttt{visitorid}, \texttt{event}, \texttt{itemid}, \texttt{transactionid}, \texttt{timestamp} & 2,756,101 rows \\ \hline
\textbf{Properties} & \texttt{item\_properties.csv} & Contains metadata and attributes for items. & \texttt{itemid}, \texttt{property}, \texttt{value}, \texttt{timestamp} & 20,275,902 rows \\ \hline
\textbf{Category Tree} & \texttt{category\_tree.csv} & Defines the hierarchical structure of item categories. & \texttt{categoryid}, \texttt{parentid} & 1,669 rows \\ \hline
\end{tabularx}
\end{table}

\subsubsection{Dataset Constraints}
\begin{itemize}
    \item \textbf{Missing \texttt{transactionid} in Events:} As noted in the Business Understanding phase, the raw \texttt{events.csv} does not contain a specific \texttt{transactionid} for grouping items into a single basket. The \texttt{transactionid} field is populated only for 'transaction' events (approx. 0.8\% of rows), leaving 99.19\% of records with null values.
    \item \textbf{Implication:} This necessitates deriving an "Average Ticket Size (ATS)" proxy rather than a precise "Order Value," which impacts how we define high-value customers.
\end{itemize}

\subsection{Data Quality Assessment}

A preliminary quality check was performed to identify missing values, duplicates, and inconsistencies.

\begin{itemize}
    \item \textbf{Events Data:}
    \begin{itemize}
        \item \textbf{Completeness:} \texttt{visitorid}, \texttt{itemid}, and \texttt{timestamp} are fully populated. \texttt{transactionid} is missing for 'view' and 'addtocart' events.
        \item \textbf{Volume:} Highly granular clickstream data with over 2.7 million interactions.
        \item \textbf{Entities:}
        \begin{itemize}
            \item Unique Visitors: \textbf{1,407,580}
            \item Unique Items: \textbf{235,061}
            \item Unique Transactions: \textbf{17,672}
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Item Properties:}
    \begin{itemize}
        \item \textbf{Completeness:} No missing values in key columns.
        \item \textbf{Variety:} Contains 1,104 unique property types. The most frequent property is \texttt{'available'} (present for all 417,053 items), indicating stock status.
        \item \textbf{Price Extraction:} Item prices are stored under property ID \texttt{'790'} and required cleaning (stripping characters like 'n') for numerical analysis.
    \end{itemize}

    \item \textbf{Category Tree:}
    \begin{itemize}
        \item \textbf{Structure:} A hierarchical tree with 1,669 categories, and we have identified 25 root nodes (1.5\%) with no \texttt{parentid} - likely related to 25 main categories.
    \end{itemize}
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{figure/25root.png}
    \caption{Sampled radial hierarchy of the RetailRocket Product Category Taxonomy}
\end{figure}


\subsection{Exploratory Data Analysis (EDA)}

\subsubsection{Event Distribution \& User Interaction}
The distribution of event types reveals a massive class imbalance typical of e-commerce platforms.

\begin{itemize}
    \item \textbf{View:} $\sim$96.7\% (2.6M+ events)
    \item \textbf{Add to Cart:} $\sim$2.5\% (69K+ events)
    \item \textbf{Transaction:} $\sim$0.8\% (22K+ events)
\end{itemize}


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/event_type_distribution.png}
    \caption{Distribution of User Events (Log scale)}
    \label{fig:Distribution of User Events (Log scale)}
\end{figure}

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Step} & \textbf{User Count} & \textbf{Retention (from Start)} & \textbf{Drop-off Rate} \\ \hline
\textbf{1. View} & 1,404,179 & 100.00\% & 0.00\% \\ \hline
\textbf{2. Add to Cart} & 37,722 & 2.69\% & \textbf{97.31\%} \\ \hline
\textbf{3. Transaction} & 11,719 & 0.83\% & \textbf{68.93\%} \\ \hline
\end{tabular}
\end{table}

\textbf{Key Observation:} The overwhelming dominance of 'view' events confirms that the vast majority of user activity is passive browsing. This highlights the challenge of identifying intent signals amidst noise.



\subsubsection{Time Analysis}

Weekly volumes of view, add-to-cart, and transaction events exhibit a stable temporal pattern, increasing from May, peaking in mid-to-late July, and declining moderately in August. This synchronized behavior across the funnel suggests mild seasonality, primarily driven by fluctuations in overall user engagement rather than changes in conversion efficiency. Moreover, the absence of abnormal drops or data gaps indicates consistent data coverage throughout the observation window, supporting the reliability of subsequent time-dependent analyses.


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/time_anal.png}
    \caption{Weekly volumes of view, add-to-cart, and transaction events over the observation period}
    \label{fig:weekly_time_anal}
\end{figure}

Building on the weekly trends, user activity shows a clear day-of-week pattern, with higher engagement on weekdays and a noticeable decline toward the weekend. This pattern is consistent across views, add-to-cart events, and transactions, suggesting that lower weekend volumes are driven by reduced overall engagement rather than changes in conversion behavior.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/day_of_week.png}
    \caption{Event volumes by day of week for views, add-to-cart, and transactions}
    \label{fig:day_of_week}
\end{figure}


\subsubsection{Item Properties \& Categories}
\begin{itemize}
    \item \textbf{Long-Tail Distribution:} Item interaction counts follow a power-law distribution. Most items have very few interactions (1-10), as shown as Figure [\ref{fig:Distribution of Events per Visitor}], while a small "head" of popular items garners the majority of attention.
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{figure/dist_event_per_visitor.png}
    \caption{Distribution of Events per Visitor}
    \label{fig:Distribution of Events per Visitor}
\end{figure}
    
\end{itemize}

\subsection{Funnel Analysis: The User Journey}

A detailed funnel analysis was conducted to map the user journey from initial interest to final purchase. This analysis reveals two critical friction points.


\subsubsection{Insights \& Strategic Implications}

\begin{enumerate}
    \item \textbf{The "Discovery" Friction (View $\to$ AddToCart):}
    \begin{itemize}
        \item \textbf{Insight:} A massive \textbf{97.3\% drop-off} occurs here. Out of 100 users, nearly 97 are essentially "Window Shoppers" with low immediate intent.
        \item \textbf{Action:} A mass-market marketing approach (e.g., blanket discounts) would yield poor ROI here. Instead, this segment needs \textbf{Engagement strategies}, such as personalized product recommendations to spark interest.
    \end{itemize}

    \item \textbf{The "Closing" Friction (AddToCart $\to$ Transaction):}
    \begin{itemize}
        \item \textbf{Insight:} Despite showing high intent by adding items to the cart, \textbf{68.9\%} of these users still abandon the process.
        \item \textbf{Action:} This group represents "Cart Abandoners" or "High Potential" users. They are the "lowest hanging fruit." Targeted interventions like \textbf{Flash Sales} or \textbf{Free Shipping} coupons could effectively nudge them over the finish line.
    \end{itemize}
\end{enumerate}


\section{Modeling}
\label{sec:modeling}

The modeling phase of this project focuses on two primary objectives: identifying distinct customer segments through unsupervised learning and predicting the future value of customers using probabilistic models.

\subsection{RFM Framework and Feature Engineering}
Before applying clustering algorithms, we transform the raw transactional and behavioral logs into an \textbf{RFM (Recency, Frequency, Monetary)} framework, which is the standard for evaluating customer value.

\begin{itemize}
    \item \textbf{Definitions and Metrics:}
    \begin{itemize}
        \item \textbf{Recency ($R$):} The number of days between the user's last interaction and the snapshot date. Lower recency indicates higher engagement.
        \item \textbf{Frequency ($F$):} The total number of unique days a customer made a purchase (transactional frequency).
        \item \textbf{Monetary ($M$):} The total revenue generated by the customer (sum of transaction prices).
    \end{itemize}
\end{itemize}

\subsection{Customer Segmentation with K-means}
To create actionable segments, the \textbf{K-means clustering} algorithm was employed. The model utilizes standardized Recency, Frequency, Monetary (RFM), aand a specialized Conversion Rate feature to group users with similar behaviors.


\begin{itemize}
    \item \textbf{Engineered Feature: Behavioral Conversion Rate:} 
    In addition to traditional RFM metrics, we introduced a specialized \textbf{Conversion Rate (CR)} to capture the efficiency of a user's journey. The formula is defined as:
    \begin{equation}
        \text{Conversion Rate} = \frac{\text{Total Transactions}}{\text{Total Views} + \text{Total Add-to-Carts} + 1}
    \end{equation}
    The inclusion of this feature is critical because RFM only accounts for purchase outcomes. In an e-commerce context, CR helps distinguish between "Window Shoppers" (high engagement but zero intent) and "Targeted Shoppers" (low interaction but high conversion). The additional $1$ serves as a \textbf{Laplace smoothing} factor, preventing division-by-zero and dampening the impact of users with very low interaction counts.
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\linewidth]{figure/rfm_kmeans.png}
        \caption{Distributions of recency, purchase frequency, monetary value, and conversion rate, illustrating highly skewed customer behavior and motivating feature transformation and scaling prior to K-means clustering}
        \label{fig:rfm_kmeans}
    \end{figure}
    \item \textbf{Skewness Analysis and Transformation:} 
    Initial analysis revealed a "long-tail" distribution across most features [\ref{fig:rfm_kmeans}], with \textit{Frequency} and \textit{Conversion Rate} showing high skewness (approx. 4.87 and 4.89). To address this, we applied a \textbf{logarithmic transformation} using \texttt{log1p} followed by \textbf{Standardization} (\texttt{StandardScaler}). This process reduced skewness, normalized the feature scales, and moved the distributions closer to a Gaussian shape, ensuring that K-means distance calculations are not dominated by outliers.

    \item \textbf{Dimensionality and Feature Correlation:} 
    After standardization, a correlation check was performed in Figure [\ref{fig:correlation matrix}]. The results showed very low correlation coefficients between the features, indicating that each variable (R, F, M, and CR) provides unique, non-redundant information about customer behavior. Consequently, we decided \textbf{not to use Principal Component Analysis (PCA)}, as maintaining the original 4-dimensional space allows for maximum interpretability of the resulting segments.
    \begin{figure}
        \centering
        \includegraphics[width=0.8\linewidth]{figure/correlation_check.png}
        \caption{Correlation Matrix (log1p + StandardScaler)}
        \label{fig:correlation matrix}
    \end{figure}

    \item \textbf{Optimal K Selection:} 
    The selection of the cluster count ($k$) was driven by two primary heuristics:
    \begin{itemize}
        \item \textbf{The Elbow Method:} We analyzed the Within-Cluster Sum of Squares (Inertia). A noticeable "elbow" appeared at $k=3$ and $k=4$, with the final inertia around 25,000. While both options are reasonable, the elbow at $k=4$ aligns better with other validation metrics.
    
        \item \textbf{Silhouette Analysis:} The model achieved a peak Silhouette Score of 0.2666 at $k=4$, indicating well-separated and cohesive clusters. This result, together with the elbow method, further \textbf{supports the choice of $k=4$} as the optimal number of clusters, as shown in Figure [\ref{fig:Elbow Method & Silhouette Score for Optimal K}].
    \end{itemize}

    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{figure/elbow_sil.png}
        \caption{Elbow Method and Silhouette Score for Optimal K}
        \label{fig:Elbow Method & Silhouette Score for Optimal K}
    \end{figure}

    \begin{itemize}
        \item \textbf{Clustering and Persona Identification:} 
        Based on the 4-cluster solution, the business can distinguish four key customer segments with unique behavioral patterns:  
        \begin{enumerate}
            \item \textbf{Loyal Customers:} Customers who purchase frequently, generate high revenue, and maintain relatively stable conversion rates.
            \item \textbf{Hibernating / At Risk:} Users with historically high value but currently showing signs of inactivity, highlighting the need for retention strategies.
            \item \textbf{Non-Transactors:} Users who interact with the platform but rarely convert, representing a segment with low purchase engagement.
            \item \textbf{Promising Users:} Highly engaged users with moderate interaction and strong conversion potential, representing an opportunity for targeted promotions.
        \end{enumerate}
        \begin{figure}[h!]
            \centering
            \includegraphics[width=1\linewidth]{figure/3d.png}
            \caption{Enter Caption}
            \label{fig:3d}
        \end{figure}
        These clusters provide a high-level understanding of customer behavior patterns. Visualization and detailed metrics for each segment are summarized in 
        Figure [\ref{fig:3d}] and Table \ref{tab:rfm_segments}, with further evaluation and analysis provided in the Evaluation section.
    \end{itemize}

\end{itemize}

\subsection{Customer Lifetime Value Modeling}

Customer Lifetime Value (CLV) is estimated using a probabilistic modeling framework that combines the \textbf{Beta Geometric / Negative Binomial Distribution (BG/NBD)} model and the \textbf{Gamma-Gamma} model. This approach decomposes customer value into two components: the expected number of future transactions and the expected monetary value per transaction. Together, these models provide a forward-looking estimate of the economic value each customer is expected to generate over a specified time horizon.

\subsubsection{BG/NBD Model}

The BG/NBD model is used to predict the expected number of future purchases by modeling customer purchasing behavior under a ``buy-till-you-die'' assumption. Customers are assumed to make repeat purchases according to a stochastic process while remaining active, with a latent probability of becoming inactive over time. The model leverages historical transaction data summarized by purchase frequency, recency, and the length of the observation period.

In this analysis, the BG/NBD model was estimated with regularization to improve numerical stability and reduce overfitting. The resulting parameter estimates $(r = 0.01,\ \alpha = 1.10,\ a = 0.59,\ b = 0.37)$ indicate substantial heterogeneity in both purchasing intensity and dropout behavior across customers, which is consistent with the highly skewed transaction patterns observed during exploratory analysis.

Model performance was assessed using a \textbf{30-day holdout period}, comparing predicted and observed transaction counts. The model demonstrates reasonable predictive accuracy at an aggregate level, with a slight tendency to overestimate total future purchases, a common characteristic of probabilistic lifetime models applied to limited observation windows.

\subsubsection{Gamma-Gamma Model}

To estimate customer spending behavior, the Gamma-Gamma model is applied to transaction monetary values. This model assumes that the average monetary value per transaction follows a Gamma distribution and is independent of the purchase frequency process. As a result, it captures long-run customer spending tendencies while smoothing short-term fluctuations in individual transactions.

The model is trained exclusively on \textbf{repeat customers} (i.e., customers with more than one observed transaction), as required by the model assumptions. For each eligible customer, the model estimates the conditional expected average transaction value, which serves as the monetary component in CLV estimation.


\subsubsection{CLV Estimation and Strategic Implications}

Final CLV estimates are obtained by combining the expected number of future purchases from the BG/NBD model with the expected monetary value per transaction from the Gamma-Gamma model. CLV is computed over configurable future horizons (e.g., one month), enabling flexible alignment with business planning cycles.

This modeling framework extends beyond descriptive segmentation methods such as K-means clustering. While clustering captures \textit{current behavioral similarities}, CLV estimation provides a \textit{forward-looking measure of customer value}, allowing the business to identify and prioritize high-potential customers for targeted retention and personalization strategies. Diagnostic visualizations and detailed evaluation of CLV predictions are presented in the Evaluation section.



\section{Evaluation}
\label{sec:evaluation}

This section evaluates the quality and usefulness of both the customer segmentation results and the probabilistic Customer Lifetime Value (CLV) models. The assessment focuses on the interpretability of the K-means clusters and the reliability of CLV predictions for strategic decision-making.

\subsection{Cluster Profiling and Strategic Validation}

To evaluate the effectiveness of the K-means clustering solution ($k=4$), we analyze the distribution of the original RFM-CR features across the identified segments. The resulting cluster centroids, reported in Table~\ref{tab:rfm_segments}, provide a concise summary of the behavioral characteristics associated with each segment.

\begin{table}[h!]
\centering
\caption{RFM Segment Metrics with Conversion Rate}
\label{tab:rfm_segments}
\begin{tabular}{lcccc}
\toprule
\textbf{Segment} & \textbf{Recency} & \textbf{Frequency} & \textbf{Monetary} & \textbf{Conversion Rate} \\
\midrule
Hibernating / At Risk & \cellcolor[HTML]{004529}\color[HTML]{F1F1F1} 101.2 days & \cellcolor[HTML]{FFFFE5}\color[HTML]{000000} 1.17 times & \cellcolor[HTML]{FFFFE5}\color[HTML]{000000} \$92,073.85 & \cellcolor[HTML]{FCFED3}\color[HTML]{000000} 20.21\% \\
Loyal Customers & \cellcolor[HTML]{BCE395}\color[HTML]{000000} 55.9 days & \cellcolor[HTML]{004529}\color[HTML]{F1F1F1} 15.42 times & \cellcolor[HTML]{004529}\color[HTML]{F1F1F1} \$1,932,792.14 & \cellcolor[HTML]{FEFFDF}\color[HTML]{000000} 18.91\% \\
Non-Transactors & \cellcolor[HTML]{FFFFE5}\color[HTML]{000000} 33.3 days & \cellcolor[HTML]{FFFFE4}\color[HTML]{000000} 1.23 times & \cellcolor[HTML]{FDFEDD}\color[HTML]{000000} \$137,567.28 & \cellcolor[HTML]{FFFFE5}\color[HTML]{000000} 18.17\% \\
Promising Users & \cellcolor[HTML]{8DCF81}\color[HTML]{000000} 63.9 days & \cellcolor[HTML]{FDFEDB}\color[HTML]{000000} 1.58 times & \cellcolor[HTML]{FCFED6}\color[HTML]{000000} \$178,140.76 & \cellcolor[HTML]{004529}\color[HTML]{F1F1F1} 57.80\% \\
\bottomrule
\end{tabular}
\end{table}


The results indicate clear behavioral separation across clusters, supporting the validity of the chosen segmentation.

\textbf{Key Insights.}
First, the \textit{Loyal Customers} segment exhibits substantially higher purchase frequency and monetary contribution compared to other groups, confirming that the clustering approach successfully isolates the core revenue-generating customers. Despite their relatively moderate recency, these customers represent the most economically valuable segment.

Second, the \textit{Promising Users} segment demonstrates the highest conversion rate (57.80\%), despite lower overall transaction volume. This suggests strong purchase intent and highlights the segment’s potential for future value growth if appropriately nurtured. In contrast, the \textit{Hibernating / At Risk} segment combines high recency with low frequency and monetary value, indicating disengagement and elevated churn risk.

Overall, the cluster profiles align well with established customer lifecycle patterns, providing a reliable historical baseline for downstream analysis.

\subsection{CLV Model Assessment and Risk Analysis}

To complement the descriptive segmentation, probabilistic CLV models are used to assess future customer value and churn risk. The relationship between the predicted Customer Lifetime Value and the estimated \textit{Probability of being Alive} ($P(\text{Alive})$) is examined to evaluate the practical interpretability of the model outputs.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{figure/clv_result.png}
    \caption{Strategic Customer Value Map: Predicted CLV vs. Probability of Being Alive}
    \label{fig:clv_evaluation_map}
\end{figure}

\subsubsection{Risk Threshold and Trend Analysis}

As shown in Figure~\ref{fig:clv_evaluation_map}, a clear log-linear relationship is observed between $P(\text{Alive})$ and predicted CLV: customers with higher survival probabilities are expected to generate disproportionately higher future value. This pattern is consistent with the underlying assumptions of the CLV framework and supports its behavioral plausibility.

To operationalize the results, a churn risk threshold is defined at $P(\text{Alive}) = 0.9$. Customers falling below this threshold are classified as having elevated churn risk. The horizontal dashed line represents the mean predicted CLV (\$207{,}530), which serves as a benchmark for distinguishing high-value from low-value customers.

This visualization enables a quadrant-based interpretation. Customers with high predicted CLV but low $P(\text{Alive})$ represent \textit{high-value at-risk} individuals, for whom targeted retention interventions are likely to yield the greatest return. Conversely, customers with both high CLV and high survival probability can be considered stable loyalists, requiring less immediate intervention. Bubble sizes, reflecting historical purchase frequency, further indicate that while higher-frequency customers tend to have higher survival probabilities, several high-frequency customers still exhibit substantial churn risk.

\subsection{Discussion}

The evaluation demonstrates that K-means clustering provides an interpretable and behaviorally coherent segmentation of historical customer activity, while the probabilistic CLV framework adds a forward-looking perspective by quantifying future value and churn risk. Importantly, the integration of these two approaches enables actionable prioritization: by cross-referencing high-value clusters with customers falling below the $P(\text{Alive}) = 0.9$ threshold, the business can allocate retention resources more efficiently toward customers who are both valuable and statistically likely to churn.



\section{Storytelling}
\label{sec:storytelling}

\subsection{The Business Context}
In a competitive e-commerce environment, ``one-size-fits-all'' marketing is the fastest way to burn budget. Our analysis of the RetailRocket dataset exposes a critical inefficiency: generic strategies are failing to capture value.

We have \textbf{1,407,580 unique visitors} but only \textbf{22,457 transactions}. This massive gap reveals that the majority of our users never reach the purchase stage. We are successfully filling the funnel, but we are facing a massive ``leaky bucket'' problem.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/overview.png}
    \caption{Executive Overview Dashboard: Setting the stakes with high traffic but low conversion.}
    \label{fig:overview}
\end{figure}

\subsection{The Conversion Rate}
To understand where the leak is, we look at the journey efficiency. The dashboard reveals a clear story of friction:
\begin{itemize}
    \item \textbf{View $\to$ Add to Cart Rate:} 2.69\%
    \item \textbf{Cart $\to$ Purchase Rate:} 31.07\%
    \item \textbf{Abandonment Rate:} \textbf{68.93\%}
\end{itemize}

\textbf{The Insight}
The largest revenue leak happens before commitment. Most users behave like ``window shoppers'' (high views, zero intent), while a small fraction are ``silent loyalists'' (high intent). Treating these two groups the same---with the same emails and the same ads---is why the abandonment rate is nearly 70\%. This motivated our engineering of the \textbf{Behavioral Conversion Rate (CR)} to separate high-engagement browsers from actual buyers.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/conversion.png}
    \caption{Conversion \& Abandonment Dashboard: Visualizing the drop-off points.}
    \label{fig:conversion}
\end{figure}

\subsection{Feature Distributions}
Before we could segment the customers, we had to address a fundamental truth: customer behavior follows a \textbf{``Long-Tail'' distribution} (Pareto Principle), not a normal distribution. A small number of ``Super Users'' generate extreme frequency and monetary values, while the vast majority cluster near zero. 

To prevent these outliers from skewing our K-means clustering, we applied \textbf{Log-Transformation ($\log1p$) and Standardization}. This step was critical to ensure that our segmentation reflects true behavioral patterns rather than just magnitude.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/feature_distribution_and_lagging.png}
    \caption{Feature Distributions \& 80/20 Indicators: Justifying the preprocessing decisions.}
    \label{fig:features}
\end{figure}

\subsection{Customers Segmentation}
After cleaning the signals, we moved from thousands of chaotic timelines to \textbf{5 distinct Customer DNA Profiles}. The 3D Cluster view allows us to see these ``tribes'' clearly.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/3D_rfm.png}
    \caption{Interactive 3D Cluster View (RFM).}
    \label{fig:3d_cluster}
\end{figure}

Using the RFM Heatmap, we define the personas and the strategy for each:

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figure/rfm_segment.png}
    \caption{RFM Profiles Heatmap by Segment.}
    \label{fig:heatmap}
\end{figure}

\begin{enumerate}
    \item \textbf{VIP Zone (Loyal Customers): The ``Whales''} \\
    Profile: High Frequency \& High Monetary. \\
    Story: The profit engine. They don't need discounts; they need exclusivity.
    
    \item \textbf{Growth Zone (Recent \& High Potential): The ``Rising Stars''} \\
    Profile: Active recently, moderate spend, but high conversion tendency. \\
    Story: They are developing loyalty. Personalization here can ``create'' future VIPs.
    
    \item \textbf{Hibernating Zone (At Risk): The ``Fading Stars''} \\
    Profile: Historically meaningful value, but inactive recently (High Recency). \\
    Story: Expensive to lose, efficient to win back. They need a ``jolt'' to reactivate.
    
    \item \textbf{Low Value Zone: The ``Bargain Hunters''} \\
    Profile: Low Spend \& Low Loyalty. \\
    Story: Best handled with automated, low-cost campaigns to increase basket size.
    
    \item \textbf{Non-Transactors: The ``Window Shoppers''} \\
    Profile: Interactions (View/Cart) but \textbf{zero} transactions. \\
    Story: The biggest segment. The goal isn't retention; it's conversion through onboarding and trust-building.
\end{enumerate}

\subsection{Future Value Prediction}
Segmentation tells us who customers were. CLV (Customer Lifetime Value) tells us who they will be. Using the \textbf{BG/NBD} (frequency prediction) and \textbf{Gamma-Gamma} (monetary prediction) models, we created a decision map that prioritizes profit over revenue.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figure/clv_map.png}
    \caption{Strategic Customer Value Map: Predicted CLV vs. Probability Alive.}
    \label{fig:clv_map}
\end{figure}

\textbf{The ``Danger Zone'' Insight:} \\
Looking at the top-left quadrant of the map (High Predicted CLV vs. Low Probability Alive), we identify our most critical risk: \textbf{High-value customers who are statistically likely to churn.}
\begin{itemize}
    \item \textbf{Strategy:} These are the highest ROI targets for retention budget.
    \item \textbf{Contrast:} Customers with High CLV and High P(Alive) are safe; they require maintenance, not emergency rescue.
\end{itemize}

\subsection{Execution Roadmap}
Finally, we convert analytics into action. Our temporal analysis revealed that \textbf{Tuesday} is the peak activity day, providing the perfect timing for our campaigns.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figure/behavioral_insights.png}
    \caption{Behavioral Insights \& Trends: Validating the ``Tuesday'' campaign timing.}
    \label{fig:behavior}
\end{figure}

Combining the \textbf{5 Clusters} with \textbf{CLV Risk} and \textbf{Peak Timing}, we propose the following phased rollout:

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{figure/action_rec.png}
    \caption{Action Recommendations Matrix.}
    \label{fig:action_matrix}
\end{figure}

\begin{description}
    \item[Phase 1: Immediate (0--30 days) -- ``Stop the Bleeding''] \hfill \\
    \textbf{Action:} Deploy segment labels to CRM. \\
    \textbf{Target:} Launch \textbf{VIP Retention} program (Early Access) and trigger \textbf{Hibernating Win-back} campaigns (using High CLV/Low P(Alive) list) specifically on Tuesdays.

    \item[Phase 2: Short-Term (1--3 months) -- ``Nurture Growth''] \hfill \\
    \textbf{Action:} Build a recommendation engine. \\
    \textbf{Target:} Focus on \textbf{Growth Zone} and \textbf{Non-Transactors} with second-purchase incentives and onboarding flows to improve the Conversion Rate.

    \item[Phase 3: Ongoing -- ``Optimize''] \hfill \\
    \textbf{Action:} Monitor segment migration. \\
    \textbf{Target:} Re-cluster quarterly to track if ``Growth'' users are graduating to ``VIP'' or sliding into ``Hibernating.''
\end{description}



\section{Discussion}
\label{sec:discussion}

This project successfully architected an end-to-end Customer Segmentation \& Personalization System, directly addressing the "leaky bucket" inefficiency where 1.4 million visitors resulted in only a 0.83\% conversion rate. By analyzing the RetailRocket dataset, we shifted from uniform marketing to a data-driven approach, utilizing K-Means clustering and probabilistic CLV modeling (BG/NBD and Gamma-Gamma) to transform raw clickstream logs into actionable customer intelligence. This framework allows the organization to understand not just past behaviors but also predict future value, identifying distinct user cohorts for targeted engagement.

The core value of this framework lies in its operational actionability through the DOC (Decision-Options-Criteria) framework. We identified distinct customer "tribes", encompassing groups such as VIPs, Hibernating users, and Promising Users, and engineered a Behavioral Conversion Rate (CR) to distinguish high-intent buyers from "Window Shoppers". Crucially, the analysis highlighted a "Danger Zone" of high-value customers with low survival probabilities ($P(Alive) < 0.9$), enabling the precise allocation of retention resources to where they yield the highest ROI rather than wasting budget on stable loyalists.

While the model offers robust insights, it faces limitations such as reliance on Average Ticket Size as a proxy for order value due to missing transaction IDs and observational bias inherent in historical data. To mitigate these risks and drive sustainable growth, future phases must implement the proposed Experimentation Framework, utilizing control groups and A/B testing to validate strategies like "Win-back" campaigns. Integrating these segment labels directly into the CRM for real-time automation will ultimately transition the system from a static analysis to a dynamic revenue-generating engine.



% bibliography

@article{10.1063/5.0299024,
    author = {Sa’diah, Dhea Halimatu and Fahrudin, Nur Fitrianti},
    title = {Customer lifetime value (CLV) analysis on customer segmentation using RFM model with k-means clustering},
    journal = {AIP Conference Proceedings},
    volume = {3351},
    number = {1},
    pages = {060012},
    year = {2025},
    month = {11},
    abstract = {The problem that companies often face is identifying the right customers, which causes the company to lose potential customers, which is detrimental to the company itself. CLV value can be used to identify the value of a customer. In identifying customer value, the RFM method can be used, which includes recency, frequency, and monetary. This RFM aims to help companies find out customer spending habits. In its implementation, the K-Means algorithm is used to help form customer segments. In this research, CLV calculation is done with RFM model and K-means clustering algorithm. The purpose of this research is to find out the right customer segment based on the CLV value. The results of CLV analysis will be compared with data visualization that displays the distribution of RFM scoring on a scale of 1-3. The CLV values that have been calculated will then be ranked from the highest to the lowest value. But after the analysis, there are differences in segmentation results based on CLV values and data visualization. This shows that CLV has not been able to analyze the right segment for customers based on the method used in this study but CLV can help identify the value of a customer in a company.},
    issn = {0094-243X},
    doi = {10.1063/5.0299024},
    url = {https://doi.org/10.1063/5.0299024},
    eprint = {https://pubs.aip.org/aip/acp/article-pdf/doi/10.1063/5.0299024/20789997/060012_1_5.0299024.pdf},
}

@article{Karvanen_2014,
   title={Survey data and Bayesian analysis: a cost-efficient way to estimate customer equity},
   volume={12},
   ISSN={1573-711X},
   url={http://dx.doi.org/10.1007/s11129-014-9148-4},
   DOI={10.1007/s11129-014-9148-4},
   number={3},
   journal={Quantitative Marketing and Economics},
   publisher={Springer Science and Business Media LLC},
   author={Karvanen, Juha and Rantanen, Ari and Luoma, Lasse},
   year={2014},
   month=jul, pages={305–329} }

@article{article,
author = {Fader, Peter and Hardie, Bruce and Lee, Ka},
year = {2005},
month = {12},
pages = {415-430},
title = {RFM and CLV: Using iso-value curves for customer base analysis},
volume = {XLII},
journal = {Journal of Marketing Research American Marketing Association ISSN},
doi = {10.1509/jmkr.2005.42.4.415}
}

@inproceedings{inproceedings,
author = {Tran, Kim-Giao and Nguyen, Van-Ho and Ho, Thanh},
year = {2021},
month = {11},
pages = {},
title = {Customer segmentation analysis and customer lifetime value prediction using Pareto/NBD and Gamma-Gamma model}
}